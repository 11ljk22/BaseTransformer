{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e3c5c4a",
   "metadata": {},
   "source": [
    "# 微调\n",
    "我们目前总是自己定义一个模型从头开始训练，但是这种做法比较耗费时间。因此我们可以采用一种更快速的方式，也就是在别人训练好的模型的基础上微调参数，让该模型快速适配我们的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654f9cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Model # 我们使用预训练的GPT2模型\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4057bf5e",
   "metadata": {},
   "source": [
    "# 增加自定义语言模型头"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb17f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Lyrics(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.gpt2 = GPT2Model.from_pretrained(\"gpt2\")\n",
    "        # 冻结GPT-2所有参数,我们只训练自己的那一层\n",
    "        for param in self.gpt2.parameters():\n",
    "            param.requires_grad = False\n",
    "        # 新增的线性层，将原GPT2输出的 768 维隐藏状态映射到自定义词表大小vocab_size\n",
    "        self.custom_head = nn.Linear(768, vocab_size)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        # 获取GPT-2的最后一层隐藏状态\n",
    "        outputs = self.gpt2(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state  # (batch_size, seq_len, 768)\n",
    "        # 映射到我们的自定义词表\n",
    "        out = self.custom_head(last_hidden_state)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974eeff",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0165345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LyricsDataset import LyricsDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "batch_size = 24\n",
    "dataset = LyricsDataset(\"../data/generate/lyrics.csv\", nrows=-1, batch_size=batch_size)\n",
    "vocab_size = len(dataset.token_to_index)\n",
    "\n",
    "model = GPT2Lyrics(vocab_size)\n",
    "\n",
    "padding_idx = dataset.token_to_index[\"<pad>\"]\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=padding_idx)\n",
    "\n",
    "lr = 1e-4  # 我们仅仅训练最后一个线性层，因此我们使用固定学习率\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c94a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = random_split(dataset, [0.9, 0.1])  # 划分训练集和测试集\n",
    "train_loader, test_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, collate_fn=dataset.collate_fn\n",
    "), DataLoader(test_dataset, batch_size=batch_size, collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d06f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evoluate(model, test_loader, device):\n",
    "    model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        for src, tgt in test_loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            pred = model(src)\n",
    "            loss = loss_fn(pred.reshape(-1, vocab_size), tgt.reshape(-1))\n",
    "            total_val_loss += loss.item()\n",
    "    return total_val_loss / len(test_loader)\n",
    "\n",
    "\n",
    "epochs = 500\n",
    "model.train().to(device)\n",
    "for epoch in range(epochs):\n",
    "    pbar = tqdm(\n",
    "        train_loader, desc=f\"[epoch {epoch + 1}/{epochs}] epoch progress\", leave=False\n",
    "    )\n",
    "    best_val_loss = 1e10\n",
    "    total_loss = 0\n",
    "    for src, tgt in pbar:\n",
    "        # 创建填充掩码(在transformers库中，填充掩码中的1代表有效token,0代表填充token,因此下面使用 != )\n",
    "        padding_mask = (src != padding_idx).long().to(device)\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        pred = model(src, padding_mask)  # 不需要因果掩码，因为GPT2模型内置\n",
    "        loss = loss_fn(pred.reshape(-1, vocab_size), tgt.reshape(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.6f}\")\n",
    "        total_loss += loss.item()\n",
    "    cur_val_loss = evoluate(model, test_loader, device)\n",
    "    if cur_val_loss < best_val_loss:\n",
    "        torch.save(model.state_dict(), f\"best_lyrics_gpt2_model.pth\") # 保存最佳模型\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        torch.save(model.state_dict(), f\"lyrics_gpt2_{epoch + 1}_model.pth\")\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(\n",
    "        f\"epoch {epoch + 1}: avg_loss: {avg_loss:.6f} ,perplexity: {torch.exp(torch.tensor(avg_loss)).item():.6f},val_loss: {cur_val_loss:.6f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a78f1b",
   "metadata": {},
   "source": [
    "# 加载训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e93beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "dataset = LyricsDataset(\"../data/generate/lyrics.csv\", nrows=-1, batch_size=batch_size)\n",
    "vocab_size = len(dataset.token_to_index)\n",
    "\n",
    "model = GPT2Lyrics(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fa6591",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = None # 替换为你保存模型文件的路径\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18ca73b",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e037763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    text: str,\n",
    "    model: nn.Module,\n",
    "    max_length: int,\n",
    "    separator: str,\n",
    "    device: str,\n",
    "    to_index: dict,\n",
    "    to_token: list,\n",
    "    tempreture: float = 0.75,\n",
    "):\n",
    "    model.eval().to(device)\n",
    "\n",
    "    def generate(splitted_text):\n",
    "        with torch.no_grad():\n",
    "            index_text = [to_index[\"<bos>\"]] + [\n",
    "                to_index[char] for char in splitted_text\n",
    "            ]  # 添加句首标记并将文本转化为索引\n",
    "            tensor_text = torch.tensor(index_text, device=device).unsqueeze(0)\n",
    "            generated = index_text.copy()\n",
    "            for _ in range(max_length):\n",
    "                pred = model(tensor_text, None)[:, -1, :] / tempreture  # 应用温度\n",
    "                # 概率采样预测\n",
    "                proba = nn.Softmax(dim=-1)(pred)\n",
    "                dist = torch.distributions.Categorical(proba)\n",
    "                next_id = dist.sample()\n",
    "                # 添加新next_id到下一次的输入中\n",
    "                tensor_text = torch.cat((tensor_text, next_id.unsqueeze(0)), dim=-1)\n",
    "                if to_token[next_id.item()] == \"<eos>\":\n",
    "                    break\n",
    "                generated.append(next_id.item())\n",
    "            return generated\n",
    "\n",
    "    generate_text = []\n",
    "    for splitted_text in text.split(\n",
    "        separator\n",
    "    ):  # 按照separator分割，分割后的每个元素作为每一句的开头\n",
    "        generate_text += list(\n",
    "            splitted_text\n",
    "        )  # 将新的splitted_text转化为列表添加到generate_text中\n",
    "        generate_text = [\n",
    "            to_token[idx] for idx in generate(generate_text)\n",
    "        ]  # 上一次的输出拼接上新加入的token作为输入，以实现上下文关联\n",
    "        generate_text.append(\"，\")  # 添加逗号\n",
    "\n",
    "    return \"\".join(generate_text).strip(\"<bos>\").replace(\"，，\", \"，\")\n",
    "\n",
    "\n",
    "text = \"玫瑰\"\n",
    "generated_lyrics = predict(\n",
    "    text,\n",
    "    model,\n",
    "    500,\n",
    "    \"/\",\n",
    "    \"cuda\",\n",
    "    dataset.token_to_index,\n",
    "    dataset.index_to_token,\n",
    "    tempreture=0.90,\n",
    ")\n",
    "\n",
    "\n",
    "generated_lyrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
